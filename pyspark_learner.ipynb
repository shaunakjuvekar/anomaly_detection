{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from pyspark import ml\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# pd.set_option('display.max_colwidth', None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('ml-anom').getOrCreate()\n",
    "processed_input = \"/data/log_data.csv\"\n",
    "\n",
    "input_df = spark.read.csv(processed_input,header='true')\n",
    "input_df.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# input_df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df2 = input_df.withColumn(\"is_private\",col(\"is_private\").cast(DoubleType())) \\\n",
    ".withColumn(\"is_root\",col(\"is_root\").cast(DoubleType())) \\\n",
    ".withColumn(\"is_failure\",col(\"is_failure\").cast(DoubleType())) \\\n",
    ".withColumn(\"time_since_last_failure_of_same_type\",col(\"time_since_last_failure_of_same_type\").cast(DoubleType())) \\\n",
    ".withColumn(\"failure_count_in_last_15_mins\",col(\"failure_count_in_last_15_mins\").cast(DoubleType())) \\\n",
    ".withColumn(\"failure_count_in_last_30_mins\",col(\"failure_count_in_last_30_mins\").cast(DoubleType())) \\\n",
    ".withColumn(\"failure_count_in_last_60_mins\",col(\"failure_count_in_last_60_mins\").cast(DoubleType())) \\\n",
    ".withColumn(\"label_auth_failure\",col(\"label_auth_failure\").cast(DoubleType())) \\\n",
    ".withColumn(\"label_break_in_attempt\",col(\"label_break_in_attempt\").cast(DoubleType())) \\\n",
    ".withColumn(\"label_connection_closed\",col(\"label_connection_closed\").cast(DoubleType())) \\\n",
    ".withColumn(\"label_disconnect\",col(\"label_disconnect\").cast(DoubleType())) \\\n",
    ".withColumn(\"label_failed_password\",col(\"label_failed_password\").cast(DoubleType())) \\\n",
    ".withColumn(\"label_invalid_user\",col(\"label_invalid_user\").cast(DoubleType())) \\\n",
    ".withColumn(\"label_no_label\",col(\"label_no_label\").cast(DoubleType())) \\\n",
    ".withColumn(\"label_no_identification\",col(\"label_no_identification\").cast(DoubleType())) \\\n",
    ".withColumn(\"class\",col(\"class\").cast(DoubleType()))\n",
    "# df2.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df2 = df2.drop(\"timestamp\", \"process_id\", \"username\", \"ip\", \"time_since_last_failure\")\n",
    "# df2.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vecCols = ['is_private', 'is_root', 'is_failure', 'time_since_last_failure_of_same_type', 'failure_count_in_last_15_mins',\n",
    "       'failure_count_in_last_30_mins', 'failure_count_in_last_60_mins','label_auth_failure', 'label_break_in_attempt',\n",
    "       'label_connection_closed', 'label_disconnect', 'label_failed_password',\n",
    "       'label_invalid_user', 'label_no_label', 'label_no_identification']\n",
    "assembler = VectorAssembler(inputCols=vecCols, outputCol=\"vectors\")\n",
    "df2 = assembler.transform(df2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train, test = df2.randomSplit([0.7, 0.3], seed = 2018)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(featuresCol = 'vectors', labelCol = 'class')\n",
    "ranF = model.fit(train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pickle.dump(model, open('ml_py_model.pkl', 'wb'))\n",
    "ranF.write().overwrite().save('ml_py_model.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassificationModel\n",
    "\n",
    "model = RandomForestClassificationModel.load('ml_py_model.pkl')\n",
    "pred = model.transform(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "eval = MulticlassClassificationEvaluator(labelCol=\"class\", predictionCol=\"prediction\")\n",
    "accuracy = eval.evaluate(pred)\n",
    "print(\"Accuracy = %s\" % (accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}